{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aae254ea",
   "metadata": {},
   "source": [
    "# Metrics Notebook\n",
    "This is a simple notebook designed to run all the metrics for a given variant of CLIP.  It expects a model as defined in the config below that is \"CLIP-like\" in that it can take in an image or text and output an embedding of some size.  The clip-like model should specifically adhere to the Clip interface defined in `models/clip.py`\n",
    "\n",
    "The four metrics we implement are outlined here: \n",
    "\n",
    "### Top-K Retrieval Accuracy.\n",
    "Given an image, we compute its CLIP embedding and retrieve the closest K captions based on cosine similarity with caption embeddings. If the target caption is within the top K, we count this as a correct retrieval. This metric is a direct proxy for classification accuracy in multimodal retrieval. It is valuable because strong cross-modal alignment should yield high retrieval accuracy. However, since our approach aims to reduce sparsity on the hypersphere, the embeddings may become less linearly separable, potentially lowering retrieval performance even as uniformity improves.\n",
    "\n",
    "### Modality Gap via Linear Separability.\n",
    "Following \\citet{modalityGAP}, we measure the modality gap between text and image embeddings by training a soft-margin SVM classifier to distinguish modality type. We evaluate classification accuracy, precision, and recall. High separability indicates a strong modality gap, which is undesirable because semantically matched image–text pairs should ideally share indistinguishable representations. Reducing modality separability would thus reflect improved multimodal coordination.\n",
    "\n",
    "### Hyperspherical Entropy Estimation.\n",
    "We measure the entropy of the embedding distribution on the hypersphere using the k-nearest neighbor–based estimator proposed by \\citet{entropy}. This estimator leverages angular distances to compute local density estimates, which are aggregated into a global entropy measure. Entropy serves as a proxy for sparsity: low entropy distributions are clustered and “spiky,” while high entropy indicates more uniform coverage of the hypersphere. Since our method encourages uniformity, we expect an increase in entropy relative to standard CLIP.\n",
    "\n",
    "### Downstream Captioning Performance (BLEU)\n",
    "Finally, we evaluate the utility of embeddings on a generative downstream task: image captioning. Image embeddings are passed into a pretrained language model to generate captions, which are compared against ground-truth captions using BLEU score. BLEU measures n-gram overlap between generated and reference text, rewarding fluency and accuracy. This extrinsic metric demonstrates how improvements in embedding geometry translate into practical benefits for end-user tasks, beyond abstract geometric properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3fa51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.clipModel import CLIPModel\n",
    "import nltk\n",
    "\n",
    "model = CLIPModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16da319",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def top_k_similarities(embeddings, query_embedding, k=5):\n",
    "    \"\"\"\n",
    "    Compute the top-k most similar embeddings to the query_embedding.\n",
    "    \n",
    "    Args:\n",
    "        embeddings (torch.Tensor): Tensor of shape (N, D) where N is the number of embeddings and D is the embedding dimension.\n",
    "        query_embedding (torch.Tensor): Tensor of shape (D,) representing the query embedding.\n",
    "        k (int): Number of top similar embeddings to return.\n",
    "\n",
    "    Returns:\n",
    "        List[Tuple[int, float]]: List of tuples containing the index and similarity score of the top-k most similar embeddings.\n",
    "    \"\"\"\n",
    "    # Compute cosine similarities\n",
    "    similarities = torch.nn.functional.cosine_similarity(embeddings, query_embedding.unsqueeze(0), dim=1)\n",
    "\n",
    "    # Get top-k indices\n",
    "    top_k_indices = similarities.topk(k).indices\n",
    "\n",
    "    # Return list of (index, similarity) tuples\n",
    "    return [(idx.item(), similarities[idx].item()) for idx in top_k_indices]\n",
    "\n",
    "def top_k_score(embedding_pairs, k=5):\n",
    "    \"\"\"\n",
    "    Given a list of (text_embedding[], image_embedding) pairs, return the percentage of texts that are in the top-k most similar to their corresponding image embeddings.\n",
    "    \"\"\"\n",
    "    correct_count = 0\n",
    "    for text_embeddings, image_embedding in embedding_pairs:\n",
    "        top_k = top_k_similarities(text_embeddings, image_embedding, k)\n",
    "        if 0 in [idx for idx, _ in top_k]:  # Assuming the correct text is always at index 0\n",
    "            correct_count += 1\n",
    "    return correct_count / len(embedding_pairs) if embedding_pairs else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b729df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "def linear_separability(image_embeddings, text_embeddings, num_epochs=100, learning_rate=1e-3):\n",
    "    \"\"\"\n",
    "    Train a linear classifier to distinguish between image and text embeddings, and report the accuracy.\n",
    "    \n",
    "    Args:\n",
    "        image_embeddings (torch.Tensor): Tensor of shape (N, D) for image embeddings.\n",
    "        text_embeddings (torch.Tensor): Tensor of shape (N, D) for text embeddings.\n",
    "        num_epochs (int): Number of training epochs.\n",
    "        learning_rate (float): Learning rate for the optimizer.\n",
    "\n",
    "    Returns:\n",
    "        float: Accuracy of the classifier on the given set.\n",
    "    \"\"\"\n",
    "    # Combine image and text embeddings\n",
    "    embeddings = torch.cat([image_embeddings, text_embeddings], dim=0)\n",
    "    labels = torch.cat([torch.zeros(image_embeddings.size(0)), torch.ones(text_embeddings.size(0))], dim=0)\n",
    "\n",
    "    # Train a linear classifier\n",
    "    classifier = nn.Linear(embeddings.size(1), 2)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(classifier.parameters(), lr=learning_rate)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = classifier(embeddings)\n",
    "        loss = criterion(outputs, labels.long())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Evaluate the classifier\n",
    "    with torch.no_grad():\n",
    "        outputs = classifier(embeddings)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        accuracy = (preds == labels).float().mean().item()\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be655bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bleu_score(predictions, references):\n",
    "    \"\"\"\n",
    "    Compute a simple BLEU score for a list of predictions and references.\n",
    "    \n",
    "    Args:\n",
    "        predictions (List[str]): List of predicted sentences.\n",
    "        references (List[str]): List of reference sentences.\n",
    "\n",
    "    Returns:\n",
    "        float: Average BLEU score across all predictions.\n",
    "    \"\"\"\n",
    "    from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "    total_score = 0.0\n",
    "    for pred, ref in zip(predictions, references):\n",
    "        ref_tokens = [ref.split()]\n",
    "        pred_tokens = pred.split()\n",
    "        score = sentence_bleu(ref_tokens, pred_tokens)\n",
    "        total_score += score\n",
    "\n",
    "    return total_score / len(predictions) if predictions else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a515b3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from scipy.special import digamma, beta\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "def knn_entropy(embeddings, k=5):\n",
    "    \"\"\"\n",
    "    Compute the k-nearest neighbor entropy estimator for hyperspherical data.\n",
    "    \n",
    "    This estimator is designed for data on a unit hypersphere and uses the \n",
    "    k-nearest neighbor approach to estimate entropy consistently.\n",
    "    \n",
    "    Args:\n",
    "        embeddings (torch.Tensor): Tensor of shape (N, D) representing N embeddings on the unit hypersphere of dimension D-1.\n",
    "        k (int): Number of nearest neighbors to consider.\n",
    "    \n",
    "    Returns:\n",
    "        float: Estimated entropy of the distribution.\n",
    "    \"\"\"\n",
    "    # Ensure embeddings are normalized to unit sphere\n",
    "    embeddings = embeddings / torch.norm(embeddings, dim=1, keepdim=True)\n",
    "    embeddings_np = embeddings.detach().cpu().numpy()\n",
    "    \n",
    "    n, d = embeddings_np.shape\n",
    "    \n",
    "    # Compute pairwise angular distances using arccos(x^T y)\n",
    "    # Since embeddings are normalized, dot product gives cosine similarity\n",
    "    dot_products = np.dot(embeddings_np, embeddings_np.T)\n",
    "    # Clamp to avoid numerical issues with arccos\n",
    "    dot_products = np.clip(dot_products, -1.0, 1.0)\n",
    "    angular_distances = np.arccos(dot_products)\n",
    "    \n",
    "    # For each point, find the k-th nearest neighbor distance\n",
    "    phi_values = []\n",
    "    for i in range(n):\n",
    "        # Get distances to all other points (excluding self)\n",
    "        distances_to_i = angular_distances[i]\n",
    "        distances_to_i = np.delete(distances_to_i, i)  # Remove self-distance (which is 0)\n",
    "        \n",
    "        # Sort and get k-th nearest neighbor distance\n",
    "        sorted_distances = np.sort(distances_to_i)\n",
    "        phi_i = sorted_distances[k-1]  # k-th nearest (0-indexed)\n",
    "        phi_values.append(phi_i)\n",
    "    \n",
    "    phi_values = np.array(phi_values)\n",
    "    \n",
    "    # Compute surface area of caps S(phi_i)\n",
    "    def hypersphere_cap_area(phi, d):\n",
    "        \"\"\"\n",
    "        Compute the area of a spherical cap with angle phi on a (d-1)-sphere.\n",
    "        \n",
    "        S(φ) = (1/2) * S_p * [1 - sgn(cos φ) * I_{cos²φ}(1/2, (p-1)/2)]\n",
    "        \n",
    "        where S_p is the surface area of the (d-1)-sphere and I is the regularized \n",
    "        incomplete beta function.\n",
    "        \"\"\"\n",
    "        # Surface area of (d-1)-sphere: S_p = 2π^(d/2) / Γ(d/2)\n",
    "        from scipy.special import gamma\n",
    "        S_p = 2 * (np.pi ** (d/2)) / gamma(d/2)\n",
    "        \n",
    "        cos_phi = np.cos(phi)\n",
    "        cos_phi_squared = cos_phi ** 2\n",
    "        \n",
    "        # Regularized incomplete beta function I_x(a,b) = B(x;a,b) / B(a,b)\n",
    "        from scipy.special import betainc\n",
    "        alpha = 0.5\n",
    "        beta_param = (d - 1) / 2\n",
    "        \n",
    "        # Handle the sign function and incomplete beta function\n",
    "        sign_cos_phi = np.sign(cos_phi)\n",
    "        incomplete_beta = betainc(alpha, beta_param, cos_phi_squared)\n",
    "        \n",
    "        cap_area = 0.5 * S_p * (1 - sign_cos_phi * incomplete_beta)\n",
    "        \n",
    "        return cap_area\n",
    "    \n",
    "    # Compute cap areas for all phi values\n",
    "    S_phi = np.array([hypersphere_cap_area(phi, d) for phi in phi_values])\n",
    "    \n",
    "    # Compute L_{n,i} = ln(f_n(X_i)) = ln(k/n / S(phi_i))\n",
    "    L_values = np.log(k/n) - np.log(S_phi)\n",
    "    \n",
    "    # Compute digamma function ψ(k)\n",
    "    psi_k = digamma(k)\n",
    "    \n",
    "    # Compute entropy using the first formulation:\n",
    "    # H_n(f) = -(1/n) * Σ[L_{n,i} - ln(k) + ψ(k)]\n",
    "    entropy = -(1/n) * np.sum(L_values - np.log(k) + psi_k)\n",
    "    \n",
    "    return entropy\n",
    "\n",
    "# Alternative implementation using the second formulation for verification\n",
    "def knn_entropy_alternative(embeddings, k=5):\n",
    "    \"\"\"\n",
    "    Alternative implementation using the second formulation:\n",
    "    H_n(f) = (1/n) * Σ ln[n * S(φ_i)] - ψ(k)\n",
    "    \"\"\"\n",
    "    # Ensure embeddings are normalized to unit sphere\n",
    "    embeddings = embeddings / torch.norm(embeddings, dim=1, keepdim=True)\n",
    "    embeddings_np = embeddings.detach().cpu().numpy()\n",
    "    \n",
    "    n, d = embeddings_np.shape\n",
    "    \n",
    "    # Compute pairwise angular distances\n",
    "    dot_products = np.dot(embeddings_np, embeddings_np.T)\n",
    "    dot_products = np.clip(dot_products, -1.0, 1.0)\n",
    "    angular_distances = np.arccos(dot_products)\n",
    "    \n",
    "    # Find k-th nearest neighbor distances\n",
    "    phi_values = []\n",
    "    for i in range(n):\n",
    "        distances_to_i = angular_distances[i]\n",
    "        distances_to_i = np.delete(distances_to_i, i)\n",
    "        sorted_distances = np.sort(distances_to_i)\n",
    "        phi_i = sorted_distances[k-1]\n",
    "        phi_values.append(phi_i)\n",
    "    \n",
    "    phi_values = np.array(phi_values)\n",
    "    \n",
    "    # Compute cap areas\n",
    "    def hypersphere_cap_area(phi, d):\n",
    "        from scipy.special import gamma, betainc\n",
    "        S_p = 2 * (np.pi ** (d/2)) / gamma(d/2)\n",
    "        cos_phi = np.cos(phi)\n",
    "        cos_phi_squared = cos_phi ** 2\n",
    "        alpha = 0.5\n",
    "        beta_param = (d - 1) / 2\n",
    "        sign_cos_phi = np.sign(cos_phi)\n",
    "        incomplete_beta = betainc(alpha, beta_param, cos_phi_squared)\n",
    "        cap_area = 0.5 * S_p * (1 - sign_cos_phi * incomplete_beta)\n",
    "        return cap_area\n",
    "    \n",
    "    S_phi = np.array([hypersphere_cap_area(phi, d) for phi in phi_values])\n",
    "    \n",
    "    # Second formulation: H_n(f) = (1/n) * Σ ln[n * S(φ_i)] - ψ(k)\n",
    "    psi_k = digamma(k)\n",
    "    entropy = (1/n) * np.sum(np.log(n * S_phi)) - psi_k\n",
    "    \n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244c77d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
