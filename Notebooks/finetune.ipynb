{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "5eafb47b",
      "metadata": {},
      "source": [
        "# Initialization and Config\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c776d2df",
      "metadata": {},
      "outputs": [],
      "source": [
        "IS_COLAB = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7833c0ce",
      "metadata": {},
      "outputs": [],
      "source": [
        "if IS_COLAB:   \n",
        "    from google.colab import userdata\n",
        "    import os\n",
        "\n",
        "    github_token = \"\"\n",
        "    github_username = \"\" # Replace with your GitHub username\n",
        "    repository_url = f\"https://{github_username}:{github_token}@github.com/neskech/Multimodal-2025.git\"\n",
        "\n",
        "    !git clone {repository_url}\n",
        "    \n",
        "\n",
        "    %cd Multimodal-2025\n",
        "    !git checkout baselines\n",
        "    !git submodule update --init --recursive\n",
        "    \n",
        "    !pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cee0a80b",
      "metadata": {},
      "outputs": [],
      "source": [
        "if not IS_COLAB: # colab does not seem to support these\n",
        "    %load_ext autoreload\n",
        "    %autoreload 2\n",
        "    %reload_ext autoreload\n",
        "\n",
        "\n",
        "import torch\n",
        "import gc\n",
        "import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import logging\n",
        "import wandb\n",
        "import os\n",
        "import sys\n",
        "import peft\n",
        "from dotenv import load_dotenv\n",
        "from typing import Literal, Union\n",
        "\n",
        "sys.path.append(\"..\")\n",
        "from Datasets.coco import CocoDataset\n",
        "from Datasets.cc12m import CC12mDataset\n",
        "from Datasets.cood import CoodDataset\n",
        "from Datasets.laion import LaionDataset\n",
        "from Models.clipModel import CLIPModel\n",
        "from Models.cloobModel import CLOOBModel\n",
        "from Models.vClipModel import VariationalCLIPModel\n",
        "from Models.alignClipModel import AlignCLIPModel\n",
        "from losses.clipLoss import ClipLoss\n",
        "from losses.cloobLoss import CLOOBLoss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9cd23854",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Type aliases for compatibility with older Python versions\n",
        "Model = Literal['CLIP', 'CLOOB', 'ALIGN']\n",
        "ModelClass = Union[CLIPModel, CLOOBModel, AlignCLIPModel]\n",
        "MODEL: Model = 'CLOOB'\n",
        "\n",
        "type Dataset = Literal['COCO', 'COOD', 'CC12M', 'LAION']\n",
        "DATASET: Dataset = 'COOD'\n",
        "\n",
        "DEVICE = None\n",
        "if torch.cuda.is_available():\n",
        "    DEVICE = 'cuda'\n",
        "elif torch.mps.is_available():\n",
        "    DEVICE = 'mps'\n",
        "else:\n",
        "    DEVICE = 'cpu'\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# Setup logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Get WANDB Key (Use a .env file to store the key)\n",
        "load_dotenv()\n",
        "WANDB_API_KEY = os.environ.get('WANDB_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ef7f680",
      "metadata": {},
      "outputs": [],
      "source": [
        "CONFIG = {\n",
        "    'NUM_EPOCHS': 15,\n",
        "    'BATCH_SIZE': 32,\n",
        "    'LEARNING_RATE': 1e-6,\n",
        "    'WEIGHT_DECAY': 1e-2,\n",
        "\n",
        "    # Scheduler parameters\n",
        "    'WARMUP_EPOCHS': 5,\n",
        "    'DECAY_EPOCHS': 10,\n",
        "\n",
        "    # To avoid gradient explosion. Set to 1 to disable\n",
        "    'GRAD_ACCUMULATION_STEPS': 1,\n",
        "    # Clip gradients to avoid explosion\n",
        "    'CLIP_GRADIENTS': True,\n",
        "    'EMPTY_CACHE_AFTER_BATCH': False,\n",
        "\n",
        "    'DATA_DIR': '../Data',\n",
        "    'TRAIN_RATIO': 0.9,\n",
        "    'TOTAL_DATAPOINTS': 9_000,\n",
        "\n",
        "    'USE_LORA': False,\n",
        "\n",
        "    'USE_WANDB': True,\n",
        "    'WANDB_RUN_NAME': f'{MODEL}_finetune_on_{DATASET}',\n",
        "    'WANDB_PREVIOUS_RUN_ID': None, # set to None if not resuming\n",
        "    'WANDB_PROJECT_NAME': 'multimodal_2025',\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3dcf6745",
      "metadata": {},
      "source": [
        "# Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e96d503",
      "metadata": {},
      "outputs": [],
      "source": [
        "num_train = int(CONFIG['TOTAL_DATAPOINTS'] * CONFIG['TRAIN_RATIO'])\n",
        "num_val = int(CONFIG['TOTAL_DATAPOINTS'] * (1.0 - CONFIG['TRAIN_RATIO']))\n",
        "\n",
        "if DATASET == 'COCO':\n",
        "    CocoDataset.download(download_script_path='../Datasets/download_coco.sh', data_dir=CONFIG['DATA_DIR'])\n",
        "    train = CocoDataset(\n",
        "        data_dir=CONFIG['DATA_DIR'],\n",
        "        split='train2017',\n",
        "        tokenize=True,\n",
        "        max_samples=num_train\n",
        "    )\n",
        "    val = CocoDataset(\n",
        "        data_dir=CONFIG['DATA_DIR'],\n",
        "        split='val2017',\n",
        "        tokenize=True,\n",
        "        max_samples=num_val\n",
        "    ) \n",
        "    collate_fn = CocoDataset.collate_function  \n",
        "elif DATASET == 'COOD':\n",
        "    CoodDataset.download(data_dir=CONFIG['DATA_DIR'])\n",
        "    all_data = CoodDataset(\n",
        "        data_dir=CONFIG['DATA_DIR'],\n",
        "        tokenize=True,\n",
        "        max_samples=CONFIG['TOTAL_DATAPOINTS']\n",
        "    )\n",
        "    train = torch.utils.data.Subset(\n",
        "        all_data,\n",
        "        range(0, num_train)\n",
        "    )\n",
        "    val = torch.utils.data.Subset(\n",
        "        all_data,\n",
        "        range(num_train, CONFIG['TOTAL_DATAPOINTS'])\n",
        "    )\n",
        "    collate_fn = CoodDataset.collate_function\n",
        "elif DATASET == 'LAION':\n",
        "    LaionDataset.download(max_samples=CONFIG['TOTAL_DATAPOINTS'], data_dir=CONFIG['DATA_DIR'])\n",
        "    all_data = LaionDataset(\n",
        "        data_dir=CONFIG['DATA_DIR'],\n",
        "        tokenize=True,\n",
        "        max_samples=CONFIG['TOTAL_DATAPOINTS']\n",
        "    )\n",
        "    train = torch.utils.data.Subset(\n",
        "        all_data,\n",
        "        range(0, num_train)\n",
        "    )\n",
        "    val = torch.utils.data.Subset(\n",
        "        all_data,\n",
        "        range(num_train, CONFIG['TOTAL_DATAPOINTS'])\n",
        "    )\n",
        "    collate_fn = LaionDataset.collate_function\n",
        "elif DATASET == 'CC12M':\n",
        "    CC12mDataset.download(max_samples=CONFIG['TOTAL_DATAPOINTS'], data_dir=CONFIG['DATA_DIR'])\n",
        "    all_data = CC12mDataset(\n",
        "        data_dir=CONFIG['DATA_DIR'],\n",
        "        tokenize=True,\n",
        "        max_samples=CONFIG['TOTAL_DATAPOINTS']\n",
        "    )\n",
        "    train = torch.utils.data.Subset(\n",
        "        all_data,\n",
        "        range(0, num_train)\n",
        "    )\n",
        "    val = torch.utils.data.Subset(\n",
        "        all_data,\n",
        "        range(num_train, CONFIG['TOTAL_DATAPOINTS'])\n",
        "    )\n",
        "    collate_fn = CC12mDataset.collate_function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c265da9",
      "metadata": {},
      "outputs": [],
      "source": [
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train,\n",
        "    CONFIG['BATCH_SIZE'],\n",
        "    shuffle=True,\n",
        "    num_workers=0,\n",
        "    pin_memory=DEVICE == 'cuda',\n",
        "    collate_fn=collate_fn\n",
        ")\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "    val,\n",
        "    CONFIG['BATCH_SIZE'],\n",
        "    shuffle=False,\n",
        "    num_workers=0,\n",
        "    pin_memory=DEVICE == 'cuda',\n",
        "    collate_fn=collate_fn\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f77a18b4",
      "metadata": {},
      "outputs": [],
      "source": [
        "logger.info(f\"Training on {len(train)} samples, validating on {len(val)} samples.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a940a115",
      "metadata": {},
      "source": [
        "# Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24411b52",
      "metadata": {},
      "outputs": [],
      "source": [
        "if MODEL == 'CLIP':\n",
        "    model = CLIPModel(DEVICE)\n",
        "    model.freeze_for_finetuning()\n",
        "    loss = ClipLoss()\n",
        "elif MODEL == 'CLOOB':\n",
        "    model = CLOOBModel(DEVICE)\n",
        "    model.freeze_for_finetuning()\n",
        "    config = model.get_config()\n",
        "    loss = CLOOBLoss(config['inv_tau'], config['scale_hopfield'], device=DEVICE)\n",
        "else:\n",
        "    model = AlignCLIPModel(DEVICE)\n",
        "    loss = None # TODO: Implement\n",
        "\n",
        "model = model.float()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c402ef8e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: This only works if you apply it to some modules\n",
        "# See https://github.com/huggingface/peft/blob/main/examples/multilayer_perceptron/multilayer_perceptron_lora.ipynb \n",
        "# See https://huggingface.co/docs/peft/en/developer_guides/custom_models\n",
        "if CONFIG['USE_LORA']:\n",
        "   # Idek what any of this does\n",
        "    lora_config = peft.LoraConfig(\n",
        "        r=8, # Rank of the low-rank matrices\n",
        "        lora_alpha=16, # Scaling factor for LoRA updates\n",
        "       # target_modules=[\"model.visual.conv1\"], # Layers to apply LoRA to (e.g., in a Transformer)\n",
        "        lora_dropout=0.1,\n",
        "        bias=\"none\",\n",
        "        task_type=peft.TaskType.FEATURE_EXTRACTION\n",
        "    )\n",
        "    model = peft.PeftModel(model, lora_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6077737e",
      "metadata": {},
      "outputs": [],
      "source": [
        "optimizer = torch.optim.AdamW(\n",
        "    model.parameters(),\n",
        "    lr=CONFIG['LEARNING_RATE'],\n",
        "    weight_decay=CONFIG['WEIGHT_DECAY']\n",
        ")\n",
        "\n",
        "# Warmup scheduler: Linear increase from 0 to target_lr\n",
        "warmup_scheduler = torch.optim.lr_scheduler.LinearLR(optimizer, start_factor=0.01, end_factor=1.0, total_iters=CONFIG['WARMUP_EPOCHS'])\n",
        "\n",
        "# Decay scheduler: Cosine annealing after warmup\n",
        "decay_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=CONFIG['DECAY_EPOCHS'])\n",
        "\n",
        "# Combine them using SequentialLR\n",
        "# The schedulers will be applied sequentially\n",
        "scheduler = torch.optim.lr_scheduler.SequentialLR(optimizer, schedulers=[warmup_scheduler, decay_scheduler], milestones=[CONFIG['WARMUP_EPOCHS']])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf4b50aa",
      "metadata": {},
      "source": [
        "# Training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e81901d",
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_epoch(\n",
        "        model: ModelClass, \n",
        "        dataloader: torch.utils.data.DataLoader, \n",
        "        optimizer: torch.optim.Optimizer, \n",
        "        criterion: torch.nn.Module, \n",
        "):\n",
        "    model.train()\n",
        "\n",
        "    progress_bar = tqdm.tqdm(dataloader, desc=\"Training Epoch\")\n",
        "    total_loss = 0.0\n",
        "    nan_count = 0\n",
        "\n",
        "    for batch_idx, (images, text_tokens) in enumerate(progress_bar):\n",
        "        images, text_tokens = images.to(DEVICE), text_tokens.to(DEVICE)\n",
        "        images = images.float()\n",
        "    \n",
        "        # Check for NaN in input (laion gives NAN's if it. can't load images)\n",
        "        if torch.isnan(images).any() or torch.isnan(text_tokens).any():\n",
        "            logger.warning(f\"NaN in input batch {batch_idx}\")\n",
        "            optimizer.zero_grad()\n",
        "            continue\n",
        "        \n",
        "        image_features = model.encode_image_tensors(images)\n",
        "        text_features = model.encode_text_tokens(text_tokens)\n",
        "    \n",
        "        # Check for NaN in features\n",
        "        if torch.isnan(image_features).any() or torch.isnan(text_features).any():\n",
        "            logger.warning(f\"NaN in features at batch {batch_idx}: Image features stats - min={image_features.min()}, max={image_features.max()}, mean={image_features.mean()}; Text features stats - min={text_features.min()}, max={text_features.max()}, mean={text_features.mean()}\")\n",
        "            nan_count += 1\n",
        "            optimizer.zero_grad()\n",
        "            continue\n",
        "        \n",
        "        loss = criterion(image_features, text_features)\n",
        "\n",
        "        # Check for NaN in loss\n",
        "        if torch.isnan(loss):\n",
        "            logger.warning(f\"NaN loss detected at batch {batch_idx}\")\n",
        "            nan_count += 1\n",
        "            optimizer.zero_grad()\n",
        "            continue\n",
        "        \n",
        "        # If not NaN, then add to total loss\n",
        "        total_loss += loss.item()\n",
        "    \n",
        "        # Scale loss for gradient accumulation\n",
        "        scaled_loss = loss / CONFIG['GRAD_ACCUMULATION_STEPS']\n",
        "        # Backward pass\n",
        "        scaled_loss.backward()\n",
        "\n",
        "        has_nan_grads = False\n",
        "        for name, param in model.named_parameters():\n",
        "            if param.grad is not None and torch.isnan(param.grad).any():\n",
        "                has_nan_grads = True\n",
        "                logger.warning(f\"NaN gradient in {name}\")\n",
        "                break\n",
        "\n",
        "        if has_nan_grads:\n",
        "            logger.warning(f\"NaN gradients detected at batch {batch_idx}, skipping update\")\n",
        "            optimizer.zero_grad()\n",
        "            continue\n",
        "\n",
        "        # Gradient accumulation and optimization step\n",
        "        if (batch_idx + 1) % CONFIG['GRAD_ACCUMULATION_STEPS'] == 0:\n",
        "            # Clip gradients to prevent explosion\n",
        "            if CONFIG['CLIP_GRADIENTS']:\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            progress_bar.set_postfix({\n",
        "                'loss': total_loss / (batch_idx + 1),\n",
        "                'nan_count': nan_count\n",
        "            })\n",
        "\n",
        "\n",
        "        if CONFIG['EMPTY_CACHE_AFTER_BATCH']:\n",
        "            torch.cuda.empty_cache()\n",
        "            gc.collect()\n",
        "\n",
        "    # Handle remaining gradients if not accumulated evenly\n",
        "    if len(dataloader) % CONFIG['GRAD_ACCUMULATION_STEPS'] != 0:\n",
        "        if CONFIG['CLIP_GRADIENTS']:\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "    epoch_loss = total_loss / len(dataloader)\n",
        "    return epoch_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9253e14",
      "metadata": {},
      "source": [
        "# Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "728ec899",
      "metadata": {},
      "outputs": [],
      "source": [
        "def validate(\n",
        "        model: ModelClass, \n",
        "        dataloader: torch.utils.data.DataLoader, \n",
        "        criterion: torch.nn.Module,\n",
        "):\n",
        "    model.eval()\n",
        "\n",
        "    progress_bar = tqdm.tqdm(dataloader, desc=\"Evaluating\")\n",
        "    total_loss = 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (images, text_tokens) in enumerate(progress_bar):\n",
        "            images, text_tokens = images.to(DEVICE), text_tokens.to(DEVICE)\n",
        "            images = images.float()\n",
        "    \n",
        "            # Check for NaN in input (laion gives NAN's if it. can't load images)\n",
        "            if torch.isnan(images).any() or torch.isnan(text_tokens).any():\n",
        "                logger.warning(f\"NaN in input batch {batch_idx}\")\n",
        "                optimizer.zero_grad()\n",
        "                continue\n",
        "            \n",
        "            image_features = model.encode_image_tensors(images)\n",
        "            text_features = model.encode_text_tokens(text_tokens)\n",
        "            \n",
        "            # Check for NaN in features\n",
        "            if torch.isnan(image_features).any() or torch.isnan(text_features).any():\n",
        "                logger.warning(f\"NaN in features at batch {batch_idx}\")\n",
        "                optimizer.zero_grad()\n",
        "                continue\n",
        "        \n",
        "            loss = criterion(image_features, text_features)\n",
        "\n",
        "            # Check for NaN loss\n",
        "            if torch.isnan(loss):\n",
        "                logger.warning(\"NaN in validation loss, skipping batch\")\n",
        "                continue\n",
        "        \n",
        "            total_loss += loss.item()\n",
        "            progress_bar.set_postfix({'loss': total_loss / (batch_idx + 1)})\n",
        "\n",
        "            if CONFIG['EMPTY_CACHE_AFTER_BATCH']:\n",
        "                torch.cuda.empty_cache()\n",
        "                gc.collect()\n",
        "\n",
        "    epoch_loss = total_loss / len(dataloader)\n",
        "    return epoch_loss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5632e2d4",
      "metadata": {},
      "source": [
        "# Full Train Eval Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49e6c694",
      "metadata": {},
      "outputs": [],
      "source": [
        "def save_checkpoint(\n",
        "    filename: str,\n",
        "    model: ModelClass, \n",
        "    optimizer: torch.optim.Optimizer, \n",
        "    train_losses: list[float],\n",
        "    val_losses: list[float],\n",
        "):\n",
        "    \"\"\"Save model checkpoint.\"\"\"\n",
        "    checkpoint = {\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'train_losses': train_losses,\n",
        "        'val_losses': val_losses,\n",
        "        'config': CONFIG,\n",
        "    }\n",
        "    torch.save(checkpoint, filename)\n",
        "    logger.info(f\"Checkpoint saved: {filename}\")\n",
        "\n",
        "def plot_losses(model_name: str, train_losses: list[float], val_losses: list[float]):\n",
        "    \"\"\"Plot training and validation losses.\"\"\"\n",
        "    if len(train_losses) == 0:\n",
        "        logger.warning(\"No losses to plot\")\n",
        "        return\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(train_losses, label='Train Loss', marker='o')\n",
        "    plt.plot(val_losses, label='Val Loss', marker='s')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title(f'{model_name.upper()} Training Curves')\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d94e147a",
      "metadata": {},
      "outputs": [],
      "source": [
        "def train( \n",
        "    num_epochs: int,\n",
        "    model: ModelClass, \n",
        "    train_loader: torch.utils.data.DataLoader,\n",
        "    val_loader: torch.utils.data.DataLoader,\n",
        "    optimizer: torch.optim.Optimizer, \n",
        "    scheduler: torch.optim.lr_scheduler.LRScheduler,\n",
        "    criterion: torch.nn.Module\n",
        "):\n",
        "    \"\"\"Train model for specified epochs.\"\"\"\n",
        "    logger.info(f\"Starting training on {DEVICE} for {num_epochs} epochs...\")\n",
        "\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    best_val_loss = float('inf')\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        logger.info(f\"\\nEpoch {epoch + 1}/{num_epochs}\")\n",
        "\n",
        "        # Train\n",
        "        train_loss = train_epoch(\n",
        "            model,\n",
        "            train_loader,\n",
        "            optimizer,\n",
        "            criterion\n",
        "        )\n",
        "        train_losses.append(train_loss)\n",
        "        logger.info(f\"Train Loss: {train_loss:.6f}\")\n",
        "\n",
        "        # Validate\n",
        "        val_loss = validate(\n",
        "            model,\n",
        "            val_loader,\n",
        "            criterion\n",
        "        )\n",
        "        val_losses.append(val_loss)\n",
        "        logger.info(f\"Val Loss: {val_loss:.6f}\")\n",
        "\n",
        "        # Skip if losses are NaN\n",
        "        if torch.isnan(torch.tensor(train_loss)) or torch.isnan(torch.tensor(val_loss)):\n",
        "            logger.error(\"NaN loss detected! Stopping training.\")\n",
        "            break\n",
        "\n",
        "        scheduler.step()\n",
        "        logger.info(f\"Learning Rate adjusted to: {scheduler.get_last_lr()[0]:.6f}\")\n",
        "\n",
        "        # Save best model\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            save_checkpoint(\n",
        "                f\"best_{MODEL}_model_on_{DATASET}.pt\", \n",
        "                model,\n",
        "                optimizer, \n",
        "                train_losses,\n",
        "                val_losses\n",
        "            )\n",
        "            logger.info(f\"âœ“ Saved best model (val_loss: {val_loss:.6f})\")\n",
        "\n",
        "        if CONFIG['USE_WANDB']:\n",
        "            wandb.log({\n",
        "                'epoch': epoch + 1,\n",
        "                'train_loss': train_loss,\n",
        "                'val_loss': val_loss,\n",
        "                'learning_rate': scheduler.get_last_lr()[0],\n",
        "            })\n",
        "\n",
        "    return train_losses, val_losses"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20c7928c",
      "metadata": {},
      "source": [
        "# WandB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "738ef514",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Use wandb? Resume Training?\n",
        "PROJECT_NAME = CONFIG['WANDB_PROJECT_NAME']\n",
        "USE_WANDB = CONFIG['USE_WANDB']\n",
        "RESUME_LOGGING = CONFIG['WANDB_PREVIOUS_RUN_ID'] is not None\n",
        "run_name = CONFIG['WANDB_RUN_NAME']\n",
        "\n",
        "if USE_WANDB:\n",
        "    wandb.login(key=WANDB_API_KEY)\n",
        "\n",
        "    if RESUME_LOGGING:\n",
        "        run_id = CONFIG['WANDB_PREVIOUS_RUN_ID']\n",
        "        run = wandb.init(\n",
        "            settings=wandb.Settings(symlink=False),\n",
        "            id=run_id,\n",
        "            resume=\"must\",\n",
        "            project=PROJECT_NAME,\n",
        "            entity=\"multimodal_2025\",\n",
        "        )\n",
        "    else:\n",
        "        run = wandb.init(\n",
        "            name=run_name,\n",
        "            reinit=True,\n",
        "            project=PROJECT_NAME,\n",
        "            config=CONFIG,\n",
        "            entity=\"multimodal_2025\",\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e5c04d08",
      "metadata": {},
      "source": [
        "# Run Training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "edadfc6a",
      "metadata": {},
      "outputs": [],
      "source": [
        "train_losses, val_losses = train(\n",
        "    CONFIG[\"NUM_EPOCHS\"],\n",
        "    model,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    optimizer,\n",
        "    scheduler,\n",
        "    loss # type: ignore\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fae0e4e8",
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_losses(MODEL, train_losses, val_losses)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "cardelephant",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
